status: 
 - refactored scripts/proppr to support 'helpers'
 - made 'show.py' a helper
 - next helper: struct-gradient.py 
 -- sg-lift, sg-lower
 -- sg-facts2queries
 -- sg-prep TRAIN.cfacts 
    -- lift the cfacts: TRAIN-o2.cfacts
    -- convert facts to queries: r(x,y) converted to r_i(x,y): TRAIN.examples TEST.examples
     --- decide how to use negative data - complete or sampling?
 -- sg-train1 TRAIN-o2.cfacts TRAIN.examples [--initRules foo.ppr] [--interpRules foo.ppr]
   -- ground
   -- gradient
   -- gradient->rules

 -- trainSG INPUT.examples INPUT.cfacts [OUTPUT.ppr]  [--initRules foo.ppr] [--maxNewRules 20] [--maxGradient 1e-6] [--interpRules foo.ppr] [--iterations 1]

 -- sl.ppr should include directives:

 ##! feature "if(P,R)" == rule "interp(%(P),X,Y) :- interp(%(R),X,Y)." 
 ...
 ... could use some magic filtering, maybe, to get rid of the chaff?

git remote -v
origin	https://github.com/TeamCohen/ProPPR.git (fetch)
origin	https://github.com/TeamCohen/ProPPR.git (push)
wcohen@glosa:~/shared-home/code/ProPPR$ git push origin srw2.0

http://ndpsoftware.com/git-cheatsheet.html

textcat problem building code:
 ~/code/prep-proppr/

monitoring performance:
 - jstack `ps -x | grep 'java' | head -1 | cut -d' ' -f1` | more


thoughts:
 I should write some code for accessing sparse vectors/matrices/tensors.
 This plus two symtabs should be good for an inferenceGraph

 sparseVec: int[] index; float[] value;
 sparseMat: int[] index; sparseVec[] value;
 sparseTens: int[] index; sparseMat[] value;
 
 for (i=0; i<tens.index.length; i++) {
   uid = tens.index[i];
   mat = tens.value[i];
   for (j=0; j<mat.index.length; j++) {
      vid = mat.index[j];
      vec = mat.value[j];
      for (k=0; k.vec.index.length; k++) {
        fid = vec.index[k];
	fval = vec.value[k];
      }
   }

 }

also: for param vectors I should write LongDense with interface Vector
and subclasses ArrayObjectVector<T>, ArrayFloatVector, and UnitVector.

should also have a LongUnitVector which also implements a LongVector interface

LongDenseVector {
   // float[] val, 
   // track virtualLength;
   public inc(k,delta) {
      growIfNeeded(k);
      val[k] += delta;
   }
   public float get(k) { return val[k]; }
}

question - should I also use this for the nodeMap part of the CompactInferenceGraph? should I include that in the proof graph?

for EdgeWeighter should include LongDenseVector + WeightingScheme
